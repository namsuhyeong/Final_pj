{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "7SeSYpkiYnPS",
        "wTofZ1sO2aFD",
        "poJ9wMtSgb8L"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMAlwYLLRfYQ"
      },
      "outputs": [],
      "source": [
        "# Word Tokenization\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "5VhFPlfuUakK"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbeGkS6pUfAa",
        "outputId": "7bc4e34f-db3b-4968-db0c-4a99683fe91d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yzH4yOEVn6r",
        "outputId": "27eba4b5-1f67-4d50-ae48-41abcb12a1f1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting JPype1>=0.7.0 (from konlpy)\n",
            "  Downloading JPype1-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.4)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (24.1)\n",
            "Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading JPype1-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (488 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.6/488.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.5.0 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab에 Mecab 설치\n",
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D35-tKilVxA2",
        "outputId": "ff36dc03-7791-43d7-888c-1110ec55133e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Mecab-ko-for-Google-Colab'...\n",
            "remote: Enumerating objects: 138, done.\u001b[K\n",
            "remote: Counting objects: 100% (47/47), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 138 (delta 26), reused 22 (delta 8), pack-reused 91 (from 1)\u001b[K\n",
            "Receiving objects: 100% (138/138), 1.72 MiB | 12.37 MiB/s, done.\n",
            "Resolving deltas: 100% (65/65), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "OEILRg5gV8If",
        "outputId": "e13a4fe0-b876-4170-d4ab-1a6137609207"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Mecab-ko-for-Google-Colab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iI3HT_U6WBjt",
        "outputId": "c535a82d-6186-440d-8cf2-3a3e514f97db"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Mecab-ko-for-Google-Colab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash install_mecab-ko_on_colab190912.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4_2w5zxWF-8",
        "outputId": "df5ad0dd-0244-42ba-db27-4a8cdbd505b6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing konlpy.....\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.5.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.4)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (24.1)\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2024-08-27 06:05:27--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.142.24, 104.192.142.26, 104.192.142.25, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.142.24|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNMIEG3Q46&Signature=J3flD7l66QWDojFl6m6v4%2FsDqYY%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEPb%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIQCkx21nV90PmyJr9e%2FCwrRwLNYdhnZ0bnxbaz%2BRh41FSQIgC6Ox8%2F1%2BSsMHcOitTfEt5gq8z1hBVxTpugoa0%2FOC3BQqsAII%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgw5ODQ1MjUxMDExNDYiDHVYuUjZ%2Fap8Jc7XDiqEAo8xyZolp2%2Bg5DqgD2jcWTFf4vOIX52cLs1LAJ2zMJAlBo5%2BOBaC%2BZC8ZwLhPC3NtKE8a8ievR5QK94c%2BKtcZtQRC0lFBOPwDHAAVYJc6chEXsj5jvI3t3J8sv8APNvfRDCgTqMi9b4dW0fwwSb5VE7ZQpngX1Z4UKhqi57mE4STq2t%2BjIGk3uYvLNVy2aa4Ic2lnbD%2FcB3UwVhTAP3MFSUO%2FxE0ggZ%2B2vBjEYuPzGs76syqvfdod4G%2FECbQQ8aGBEWfTmoF4TEFJ65IufsWh69eSzWVxpum3K0mXbcSTXYA9TvmiFrHR2mAXp9LoQCNUjoaX%2FJel79H184E%2FoFQ06iapSZyMI3WtbYGOp0BcuDSuQz%2FpjBlvHxNT%2FwtYHTwA%2FFRjWCQH3ofNSwJbHnT3i4Z2b6IC7%2FlgkkymMfQPToT94zEPNAvKPlPNKn%2BwxcvKvqGIrrvSDoOXJSSGOVR0iRMdntkcZ9NKUsTSK1CTDDYrmjOPq7A6C0bEtb3ar3jwLpo3TpOAgGXNbZmUp2uxcG5Z7ymadsyM5n%2BZweq01PIT8I6Ex09nmBprQ%3D%3D&Expires=1724740117 [following]\n",
            "--2024-08-27 06:05:28--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNMIEG3Q46&Signature=J3flD7l66QWDojFl6m6v4%2FsDqYY%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEPb%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIQCkx21nV90PmyJr9e%2FCwrRwLNYdhnZ0bnxbaz%2BRh41FSQIgC6Ox8%2F1%2BSsMHcOitTfEt5gq8z1hBVxTpugoa0%2FOC3BQqsAII%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgw5ODQ1MjUxMDExNDYiDHVYuUjZ%2Fap8Jc7XDiqEAo8xyZolp2%2Bg5DqgD2jcWTFf4vOIX52cLs1LAJ2zMJAlBo5%2BOBaC%2BZC8ZwLhPC3NtKE8a8ievR5QK94c%2BKtcZtQRC0lFBOPwDHAAVYJc6chEXsj5jvI3t3J8sv8APNvfRDCgTqMi9b4dW0fwwSb5VE7ZQpngX1Z4UKhqi57mE4STq2t%2BjIGk3uYvLNVy2aa4Ic2lnbD%2FcB3UwVhTAP3MFSUO%2FxE0ggZ%2B2vBjEYuPzGs76syqvfdod4G%2FECbQQ8aGBEWfTmoF4TEFJ65IufsWh69eSzWVxpum3K0mXbcSTXYA9TvmiFrHR2mAXp9LoQCNUjoaX%2FJel79H184E%2FoFQ06iapSZyMI3WtbYGOp0BcuDSuQz%2FpjBlvHxNT%2FwtYHTwA%2FFRjWCQH3ofNSwJbHnT3i4Z2b6IC7%2FlgkkymMfQPToT94zEPNAvKPlPNKn%2BwxcvKvqGIrrvSDoOXJSSGOVR0iRMdntkcZ9NKUsTSK1CTDDYrmjOPq7A6C0bEtb3ar3jwLpo3TpOAgGXNbZmUp2uxcG5Z7ymadsyM5n%2BZweq01PIT8I6Ex09nmBprQ%3D%3D&Expires=1724740117\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.216.29.204, 52.216.178.19, 52.217.120.161, ...\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.216.29.204|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-08-27 06:05:28 (11.5 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2024-08-27 06:08:12--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.142.24, 104.192.142.26, 104.192.142.25, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.142.24|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNHEO42O2O&Signature=DT5qCZHFXb%2Fv3BGKzB2QuPs99fQ%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEPb%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIBPcVMnZo%2BXbyyRDIYkzEaPQp2NoHI%2B1Idcq3h2B8lr5AiEA0ElJXl1AbFUwW%2Btz93OgLJukrgchj11fl3q1qONsn7UqsAII%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgw5ODQ1MjUxMDExNDYiDDthJoRd5oaZPqH2YCqEAvvEZhxqS7WoNgv5O8VNCy8FLCx09N69wYp62t8CjJz%2Bo24rtht9F%2BeS9N84jTHhOTYsJhTOhRhRj7BtvcHpqpoSlHar%2FE63Dfx4GAh0EGyU%2BEv%2B4gC0M7nEcjKD2B9lUbPQ29wR1iKgjJP5O2zrCNFLfkkmWc6CO8VdthYCIMTD3MahEktSXip%2BSrxBXmVzdVYAD8rtdKkFV7D3raOAsnUhn5LGr0P4YMNe%2BXZ6tApdffRAHcQQt84mM%2BWMECC0DSFgBFnqmYxAati17uswNhcdy3MUeAena4JM3tCHsEwt7t4g7XxTvg8CTjrN%2BVsgluRqgHWwUvRZBPASMTgbghlZGsniMI%2FXtbYGOp0BH6nWi6Xw2Yzh3xFwJQl2xVCWlvcDLUTQVTqJ0fMFRU2EgTTfdwXWJSkYqHfMq%2BG%2FLGIrZjyG7MKFJ8QOglFASuYgcQig%2F%2F%2BDOnxbwUfB9TeAj%2BtWSUcac33Ti6KU1nm2l1qhHgaivbVFjDxUOV31gDMlBBAmSJ%2FWQFcXiGkTcATEU9TUAsUEl9xWx33bQ%2BnpaS6y7ylDSnPraQwtJQ%3D%3D&Expires=1724740247 [following]\n",
            "--2024-08-27 06:08:12--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNHEO42O2O&Signature=DT5qCZHFXb%2Fv3BGKzB2QuPs99fQ%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEPb%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIBPcVMnZo%2BXbyyRDIYkzEaPQp2NoHI%2B1Idcq3h2B8lr5AiEA0ElJXl1AbFUwW%2Btz93OgLJukrgchj11fl3q1qONsn7UqsAII%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgw5ODQ1MjUxMDExNDYiDDthJoRd5oaZPqH2YCqEAvvEZhxqS7WoNgv5O8VNCy8FLCx09N69wYp62t8CjJz%2Bo24rtht9F%2BeS9N84jTHhOTYsJhTOhRhRj7BtvcHpqpoSlHar%2FE63Dfx4GAh0EGyU%2BEv%2B4gC0M7nEcjKD2B9lUbPQ29wR1iKgjJP5O2zrCNFLfkkmWc6CO8VdthYCIMTD3MahEktSXip%2BSrxBXmVzdVYAD8rtdKkFV7D3raOAsnUhn5LGr0P4YMNe%2BXZ6tApdffRAHcQQt84mM%2BWMECC0DSFgBFnqmYxAati17uswNhcdy3MUeAena4JM3tCHsEwt7t4g7XxTvg8CTjrN%2BVsgluRqgHWwUvRZBPASMTgbghlZGsniMI%2FXtbYGOp0BH6nWi6Xw2Yzh3xFwJQl2xVCWlvcDLUTQVTqJ0fMFRU2EgTTfdwXWJSkYqHfMq%2BG%2FLGIrZjyG7MKFJ8QOglFASuYgcQig%2F%2F%2BDOnxbwUfB9TeAj%2BtWSUcac33Ti6KU1nm2l1qhHgaivbVFjDxUOV31gDMlBBAmSJ%2FWQFcXiGkTcATEU9TUAsUEl9xWx33bQ%2BnpaS6y7ylDSnPraQwtJQ%3D%3D&Expires=1724740247\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 54.231.199.129, 3.5.11.202, 52.216.213.73, ...\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|54.231.199.129|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  44.8MB/s    in 1.1s    \n",
            "\n",
            "2024-08-27 06:08:14 (44.8 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "apt-get update\n",
            "apt-get upgrade\n",
            "apt install curl\n",
            "apt install git\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
            "Done\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n",
            "사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n",
            "NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n",
            "블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y fonts-nanum\n",
        "!apt-get install -y fontconfig\n",
        "!fc-cache -fv\n",
        "!pip install MeCab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKjM9gjQWKKs",
        "outputId": "ad393426-3678-4c75-ea52-6b91adb13452"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  fonts-nanum\n",
            "0 upgraded, 1 newly installed, 0 to remove and 4 not upgraded.\n",
            "Need to get 10.3 MB of archives.\n",
            "After this operation, 34.1 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-nanum all 20200506-1 [10.3 MB]\n",
            "Fetched 10.3 MB in 1s (19.4 MB/s)\n",
            "Selecting previously unselected package fonts-nanum.\n",
            "(Reading database ... 123594 files and directories currently installed.)\n",
            "Preparing to unpack .../fonts-nanum_20200506-1_all.deb ...\n",
            "Unpacking fonts-nanum (20200506-1) ...\n",
            "Setting up fonts-nanum (20200506-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "fontconfig is already the newest version (2.13.1-4.2ubuntu5).\n",
            "fontconfig set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 4 not upgraded.\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/nanum: caching, new cache contents: 12 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/usr/share/fonts/truetype: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/humor-sans: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/liberation: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/nanum: skipping, looped directory detected\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n",
            "Collecting MeCab\n",
            "  Downloading mecab-0.996.3.tar.gz (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: MeCab\n",
            "  Building wheel for MeCab (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for MeCab: filename=mecab-0.996.3-cp310-cp310-linux_x86_64.whl size=167496 sha256=05d6d0bd9fb00a0ac90338fe33e3c44be52f4340d7945bb4f67988a5ae58fab5\n",
            "  Stored in directory: /root/.cache/pip/wheels/10/1a/b2/8c0e17d02a12c7b46e3065f55aa7555d173a5b020110717829\n",
            "Successfully built MeCab\n",
            "Installing collected packages: MeCab\n",
            "Successfully installed MeCab-0.996.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import *\n",
        "\n",
        "mecab = Mecab()\n",
        "\n",
        "# nouns : 명사 추출\n",
        "# morphs : 형태소 추출\n",
        "# pos : part of speech 품사"
      ],
      "metadata": {
        "id": "gtTRGjJEWkE5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/filtered_flood_news_ver02.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "VxnbbqJay1dq",
        "outputId": "701bb3b3-95e0-4933-f48f-41876bf85198"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     제목  \\\n",
              "0  [물순환] 제주 수자원 보호 '자연적 빗물 흐름 관리' 과제 대두   \n",
              "1               (전기기술사의 품격)이성근 전기철도 기술사   \n",
              "2      서울 내 정화조 50년만에 사라지나…'악취근원' 폐쇄 시동   \n",
              "3         서울 내 노후화된 하수도 정비…IoT·ICT기술 접목   \n",
              "4                  서울 하수도 악취 원인 정화조 없앤다   \n",
              "\n",
              "                                             content    언론사          날짜  \\\n",
              "0  결국 지하수 함량은 줄어들고 빗물이 도로 등을 따라 저지대로 흐르면서 침수피해가 커...   제민일보  2018-01-01   \n",
              "1  전남 해남 출신으로 서울시립대에서 전자공학을 전공했다. 군대 제대 후 1987년 서...   전기신문  2018-01-09   \n",
              "2  서울시는 \"이런 내용으로 대대적 정비가 이뤄지면 시민 생활이 편리해지는 것과 동시에...   연합뉴스  2018-01-10   \n",
              "3  이어 '도시 침수'(15.7%), '정화조 청소'(9.8%) 순이었다. 한제현 시 ...  아시아경제  2018-01-10   \n",
              "4  특히 30년 이상 노후화된 하수관로는 약 절반에 달해 침수, 통수불량, 하수유출, ...   이데일리  2018-01-10   \n",
              "\n",
              "                                                  링크    연도  \n",
              "0  http://www.jemin.com/news/articleView.html?idx...  2018  \n",
              "1  http://www.electimes.com/article.php?aid=15136...  2018  \n",
              "2  http://app.yonhapnews.co.kr/YNA/Basic/SNS/r.as...  2018  \n",
              "3  http://www.asiae.co.kr/news/view.htm?idxno=201...  2018  \n",
              "4  http://www.edaily.co.kr/news/newspath.asp?news...  2018  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d79a4a66-6cdc-437c-8f26-7ae7a5f19628\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>제목</th>\n",
              "      <th>content</th>\n",
              "      <th>언론사</th>\n",
              "      <th>날짜</th>\n",
              "      <th>링크</th>\n",
              "      <th>연도</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[물순환] 제주 수자원 보호 '자연적 빗물 흐름 관리' 과제 대두</td>\n",
              "      <td>결국 지하수 함량은 줄어들고 빗물이 도로 등을 따라 저지대로 흐르면서 침수피해가 커...</td>\n",
              "      <td>제민일보</td>\n",
              "      <td>2018-01-01</td>\n",
              "      <td>http://www.jemin.com/news/articleView.html?idx...</td>\n",
              "      <td>2018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(전기기술사의 품격)이성근 전기철도 기술사</td>\n",
              "      <td>전남 해남 출신으로 서울시립대에서 전자공학을 전공했다. 군대 제대 후 1987년 서...</td>\n",
              "      <td>전기신문</td>\n",
              "      <td>2018-01-09</td>\n",
              "      <td>http://www.electimes.com/article.php?aid=15136...</td>\n",
              "      <td>2018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>서울 내 정화조 50년만에 사라지나…'악취근원' 폐쇄 시동</td>\n",
              "      <td>서울시는 \"이런 내용으로 대대적 정비가 이뤄지면 시민 생활이 편리해지는 것과 동시에...</td>\n",
              "      <td>연합뉴스</td>\n",
              "      <td>2018-01-10</td>\n",
              "      <td>http://app.yonhapnews.co.kr/YNA/Basic/SNS/r.as...</td>\n",
              "      <td>2018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>서울 내 노후화된 하수도 정비…IoT·ICT기술 접목</td>\n",
              "      <td>이어 '도시 침수'(15.7%), '정화조 청소'(9.8%) 순이었다. 한제현 시 ...</td>\n",
              "      <td>아시아경제</td>\n",
              "      <td>2018-01-10</td>\n",
              "      <td>http://www.asiae.co.kr/news/view.htm?idxno=201...</td>\n",
              "      <td>2018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>서울 하수도 악취 원인 정화조 없앤다</td>\n",
              "      <td>특히 30년 이상 노후화된 하수관로는 약 절반에 달해 침수, 통수불량, 하수유출, ...</td>\n",
              "      <td>이데일리</td>\n",
              "      <td>2018-01-10</td>\n",
              "      <td>http://www.edaily.co.kr/news/newspath.asp?news...</td>\n",
              "      <td>2018</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d79a4a66-6cdc-437c-8f26-7ae7a5f19628')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d79a4a66-6cdc-437c-8f26-7ae7a5f19628 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d79a4a66-6cdc-437c-8f26-7ae7a5f19628');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-dbe2f18d-754f-4f04-bc54-cfb0ddfdd0d1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dbe2f18d-754f-4f04-bc54-cfb0ddfdd0d1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-dbe2f18d-754f-4f04-bc54-cfb0ddfdd0d1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 6357,\n  \"fields\": [\n    {\n      \"column\": \"\\uc81c\\ubaa9\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6357,\n        \"samples\": [\n          \"\\ud55c\\uac15 \\uc218\\uc704 4.9m\\uae4c\\uc9c0 \\ucc28\\uc62c\\ub790\\ub2e4\\u2026\\uc7a0\\uc218\\uad50 \\ubcf4\\ud589 \\ud1b5\\uc81c \\uc784\\ubc15\",\n          \"\\ud504\\ub9ac\\ubbf8\\uc5c4 \\uc544\\ud30c\\ud2b8 \\ube0c\\ub79c\\ub4dc \\u2018\\uc790\\uc774\\u2019\\uc758 \\ucd94\\ub77d\",\n          \"\\uc11c\\uc6b8\\uc2dc, '2019 \\uc5ec\\ub984\\ucca0 \\uc885\\ud569\\ub300\\ucc45'\\u2026\\ud3ed\\uc5fcTF \\uac00\\ub3d9\\ud574 \\uc0c1\\uc2dc\\ub300\\ube44\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6357,\n        \"samples\": [\n          \"\\uc11c\\uc6b8\\uc2dc \\ub0b4 \\uc9c0\\ud558\\ucca0 \\ub4f1 \\ub300\\uc911\\uad50\\ud1b5\\uc740 \\uc815\\uc0c1\\uc801\\uc73c\\ub85c \\uc6b4\\ud589 \\uc911\\uc785\\ub2c8\\ub2e4. \\uc11c\\uc6b8 27\\uac1c \\ud558\\ucc9c \\ucd9c\\uc785\\uc740 \\ubaa8\\ub450 \\ud1b5\\uc81c\\ub41c \\uc0c1\\ud669\\uc785\\ub2c8\\ub2e4. \\uc624\\ub298 \\ubc24 \\uc11c\\uc6b8\\uc5d0\\ub3c4 \\ub9ce\\uc740 \\ube44\\uac00 \\uc608\\uc0c1\\ub418\\ub294 \\ub9cc\\ud07c \\uc9c0\\ud558\\ucc28\\ub3c4 \\ub4f1 \\uc0c1\\uc2b5 \\uce68\\uc218\\uad6c\\uac04\\uc744 \\uc9c0\\ub098\\uc2e4 \\ub54c \\uc8fc\\uc758\\uac00 \\ud544\\uc694\\ud569\\ub2c8\\ub2e4. (\\uc601\\uc0c1\\ucde8\\uc7ac : \\ucd5c\\ub300\\uc6c5, \\uc601\\uc0c1\\ud3b8\\uc9d1 : \\uc774\\uc18c\\uc601, \\ud604\\uc7a5\\uc9c4\\ud589 : \\uae40\\ub300\\ucca0)\",\n          \"\\uc11c\\uc6b8\\uc2dc\\uc640 \\uc911\\uad6c\\uccad, GS\\uac74\\uc124\\uc758 \\ud569\\ub3d9 \\uc810\\uac80 \\uacb0\\uacfc \\ud30c\\uc190\\ub41c \\ubd80\\ubd84\\uc740 \\ube44(\\u975e)\\ub0b4\\ub825\\ubcbd\\uc73c\\ub85c \\ub2f9\\uc7a5 \\uc548\\uc804\\uc5d0\\ub294 \\ud070 \\ubb38\\uc81c\\uac00 \\uc5c6\\ub2e4\\ub294 \\uacb0\\ub860\\uc774 \\ub098\\uc654\\uc9c0\\ub9cc \\uc8fc\\ubbfc\\ub4e4\\uc740 \\ubd88\\uc548\\uc5d0 \\ub5a8\\uace0 \\uc788\\ub2e4. 3\\uc6d4 \\uc785\\uc8fc\\uac00 \\uc2dc\\uc791\\ub41c \\uac15\\ub0a8\\uad6c \\u2018\\uac1c\\ud3ec\\uc790\\uc774\\ud504\\ub808\\uc9c0\\ub358\\uc2a4\\u2019\\ub294 6\\uc6d4\\uacfc 7\\uc6d4 \\ub450 \\ucc28\\ub840 \\ud3ed\\uc6b0\\ub85c \\ub2e8\\uc9c0 \\uc77c\\ubd80\\uac00 \\uce68\\uc218\\ub3fc \\uc8fc\\ubbfc\\ub4e4\\uc758 \\uc6d0\\uc131\\uc744 \\uc0c0\\ub2e4. \\uacf5\\uc0ac\\uac00 \\ud55c\\ucc3d\\uc778 \\uc11c\\uc6b8 \\ub3d9\\ub300\\ubb38\\uad6c...\",\n          \"\\uff3b\\uba54\\ub514\\uceec\\ud22c\\ub370\\uc774 \\uc774\\ud55c\\uc194 \\uae30\\uc790\\uff3d \\ub18d\\ucd0c\\uc778\\uc801\\uc790\\uc6d0\\uac1c\\ubc1c\\uc13c\\ud130\\uc7a5 \\uae40\\ubd80\\uc131 \\uc11c\\uc6b8\\uc2dc\\ub294 \\ud3ed\\uc5fc\\u00b7\\ud3ed\\uc6b0 \\ub4f1 \\uc5ec\\ub984\\ucca0 \\uc7ac\\ud574\\uc640 \\uac01\\uc885 \\uc548\\uc804\\uc0ac\\uace0 \\ubc1c\\uc0dd\\uc5d0 \\ub300\\ube44\\ud558\\uc5ec, \\ud3ed\\uc5fc\\u00b7\\uc218\\ubc29... \\ubcf8\\uaca9\\uc801\\uc778 \\uc6b0\\uae30\\uc5d0 \\uc811\\uc5b4\\ub4e4\\uae30 \\uc804\\uc778 6\\uc6d4\\uae4c\\uc9c0 \\uce68\\uc218\\ucde8\\uc57d\\uc9c0\\uc5ed 8\\uac1c\\uc18c(\\uac15\\ub0a8\\uc5ed, \\uc0ac\\ub2f9\\uc5ed, \\uae38\\ub3d9 \\uc77c\\ub300 \\ub4f1)\\uc5d0 \\ub300\\ud55c \\ube57\\ubb3c\\ud38c\\ud504\\uc7a5 \\uc99d\\uc124, \\ud558\\uc218\\uad00\\uac70 \\ub4f1 \\ubc29\\uc7ac\\uc2dc\\uc124 \\uc815\\ube44\\ub97c \\ucca0\\uc800\\ud788...\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc5b8\\ub860\\uc0ac\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 510,\n        \"samples\": [\n          \"\\ub274\\uc2a4\\uc6cc\\uce58\",\n          \"\\uacbd\\uae30\\uc77c\\ubcf4\\uc5b8\\ub860\\uc0ac \\uc120\\uc815\",\n          \"\\ucf54\\uba54\\ub514\\ub2f7\\ucef4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ub0a0\\uc9dc\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 990,\n        \"samples\": [\n          \"2019-12-27\",\n          \"2020-12-30\",\n          \"2022-08-19\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ub9c1\\ud06c\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6357,\n        \"samples\": [\n          \"https://news.sbs.co.kr/news/endPage.do?news_id=N1007267161&plink=ORI&cooper=NAVER\",\n          \"https://weekly.donga.com/3/all/11/4288765/1\",\n          \"http://www.mdtoday.co.kr/mdtoday/index.html?no=354349\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc5f0\\ub3c4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 2018,\n        \"max\": 2024,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          2018,\n          2019,\n          2023\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "id": "rgnTcAuN3V8X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3d786b8-73c6-4ab7-949e-c6d305f6dab2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6357"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MeCab\n"
      ],
      "metadata": {
        "id": "2KnxTWg5dJb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import MeCab\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "\n",
        "# MeCab 토크나이저 생성\n",
        "mecab = MeCab.Tagger()\n",
        "\n",
        "# 사용자 정의 불용어 목록\n",
        "stopwords_ = []\n",
        "with open(\"test.txt\", \"r\") as file:\n",
        "    for i in file:\n",
        "        stopwords_.append(i.strip())\n",
        "\n",
        "stopwords = stopwords_\n",
        "# MeCab을 이용한 토큰화 함수 정의\n",
        "def mecab_tokenizer(text):\n",
        "    # MeCab을 사용하여 형태소 단위로 텍스트를 분리\n",
        "    node = mecab.parseToNode(text)\n",
        "    tokens = []\n",
        "    while node:\n",
        "        token = node.surface\n",
        "        if token and token not in stopwords and len(token) >= 2:  # 불용어 제거 및 길이가 2 이상인 단어만 추가\n",
        "            tokens.append(token)\n",
        "        node = node.next\n",
        "    return tokens\n",
        "\n",
        "# 본문 데이터를 전처리하여 리스트로 변환\n",
        "documents = []\n",
        "for sentence in tqdm(df['content'].apply(lambda x: re.sub(r\"[^a-zA-Z0-9ㄱ-ㅎ가-힣']\", \" \", x))):\n",
        "    documents.append(sentence)\n",
        "\n",
        "# TfidfVectorizer에 MeCab 기반의 커스텀 토크나이저 적용\n",
        "vectorizer = TfidfVectorizer(tokenizer=mecab_tokenizer)\n",
        "tfidf_matrix = vectorizer.fit_transform(documents)\n",
        "\n",
        "# TF-IDF 벡터 출력 (데이터프레임으로 변환)\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "# 각 단어의 빈도 수 계산\n",
        "word_counts = Counter()\n",
        "for sent in tfidf_df.columns:\n",
        "    word_counts[sent] = tfidf_df[sent].sum()\n",
        "\n",
        "# 총 단어 수 출력\n",
        "print(\"총 단어 수:\", len(word_counts))\n",
        "\n",
        "# 등장 빈도 수 상위 50개 단어\n",
        "vocab = sorted(word_counts, key=word_counts.get, reverse=True) # 내림차순\n",
        "print('등장 빈도 수 상위 50개 단어:', vocab[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vq9hRPUadI8w",
        "outputId": "b5aa201b-4d90-4453-8806-479797bb146b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6357/6357 [00:00<00:00, 843024.87it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 단어 수: 11994\n",
            "등장 빈도 수 상위 50개 단어: ['침수', '피해', '주택', '지역', '반지하', '통제', '도로', '시설', '가구', '설치', '안전', '지원', '빗물', '발생', '사업', '지하', '한강', '취약', '폭우', '집중호우', '재난', '대책', '방지', '차량', '호우', '점검', '대비', '상황', '수위', '우려', '배수', '시간', '시민', '터널', '하천', '위험', '주거', '복구', '계획', '본부', '예방', '사고', '교통', '관리', '공원', '공사', '지난해', '추진', '자치구', '시내', '주민', '현재', '현장', '상습', '빗물받이', '물막', '강남역', '대응', '정비', '조사', '일부', '대상', '동부간선도로', '전면', '집중', '올해', '인한', '기준', '운행', '태풍', '수해', '개선', '일대', '경우', '통해', '대피', '통행', '도시', '경보', '이상', '풍수', '환경', '인해', '지하차도', '함께', '진행', '여름철', '긴급', '저지대', '실시', '잠수교', '곳곳', '특히', '펌프', '선정', '거주', '관악구', '필요', '가운데', '양방향']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_articles(df, vocab, tfidf_per_article, n, m):\n",
        "    \"\"\"\n",
        "    상위 n개의 단어를 사용해 TF-IDF 점수를 계산하고, 상위 m개의 기사를 추출합니다.\n",
        "\n",
        "    Parameters:\n",
        "    - df: 원본 데이터프레임 (기사 정보 포함)\n",
        "    - vocab: 단어 빈도 리스트 (내림차순)\n",
        "    - tfidf_per_article: 기사별 TF-IDF 데이터프레임\n",
        "    - n: 상위 단어의 개수\n",
        "    - m: 추출할 상위 기사의 개수\n",
        "\n",
        "    Returns:\n",
        "    - top_m_df: 상위 m개의 기사를 포함한 데이터프레임\n",
        "    \"\"\"\n",
        "\n",
        "    # 등장 빈도 상위 n개 단어 추출\n",
        "    top_n_vocab = vocab[:n]\n",
        "\n",
        "    # 상위 n개 단어의 TF-IDF 점수를 각 기사별로 합산\n",
        "    tfidf_per_article_top_n = tfidf_per_article[top_n_vocab].sum(axis=1)\n",
        "\n",
        "    # 기사별 점수에 따라 내림차순으로 정렬\n",
        "    ranked_articles = tfidf_per_article_top_n.sort_values(ascending=False)\n",
        "\n",
        "    # 상위 m개의 기사 인덱스 추출\n",
        "    top_m_articles = ranked_articles.head(m).index\n",
        "\n",
        "    # 상위 m개 기사의 순위, 제목, 날짜, 내용, TF-IDF 점수를 데이터프레임으로 정리\n",
        "    top_m_df = pd.DataFrame({\n",
        "        '제목': df['제목'].iloc[top_m_articles].values,  # 기사 제목\n",
        "        '날짜': df['날짜'].iloc[top_m_articles].values,   # 기사 날짜\n",
        "        '내용': df['content'].iloc[top_m_articles].values, # 기사 내용\n",
        "        'TF-IDF 점수 합': ranked_articles.head(m).values   # TF-IDF 점수 합\n",
        "    })\n",
        "\n",
        "    return top_m_df\n"
      ],
      "metadata": {
        "id": "8Iuq2aySdNvs"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 기사의 TF-IDF 점수를 DataFrame 형태로 변환\n",
        "tfidf_per_article = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "# 상위 100개 단어와 빈도수를 데이터프레임으로 정리\n",
        "top_n_word_counts = {word: word_counts[word] for word in vocab[:100]}\n",
        "top_n_df = pd.DataFrame(list(top_n_word_counts.items()), columns=['단어', '빈도수'])\n",
        "# 결과 출력 및 저장\n",
        "print(top_n_df)\n",
        "\n",
        "top_n_df.to_csv('TF_top100.txt', sep = '\\t')\n",
        "\n",
        "df = pd.read_csv('/content/filtered_flood_news_ver02.csv')\n",
        "top_20vocab_20percent = get_top_articles(df, vocab, tfidf_per_article, 20, len(df))\n",
        "top_50vocab_20percent = get_top_articles(df, vocab, tfidf_per_article, 50, len(df))\n",
        "top_100vocab_20percent = get_top_articles(df, vocab, tfidf_per_article, 100, len(df))\n",
        "# 결과 출력\n",
        "top_20vocab_20percent.to_csv('top_20vocab_20percent.csv')\n",
        "top_50vocab_20percent.to_csv('top_50vocab_20percent.csv')\n",
        "top_100vocab_20percent.to_csv('top_100vocab_20percent.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRkjy9e9fdBA",
        "outputId": "2e80c7d1-d544-45cb-9c4d-271c7e06b7d6"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     단어         빈도수\n",
            "0    침수  254.233399\n",
            "1    피해  198.271665\n",
            "2    주택  175.440925\n",
            "3    지역  164.985779\n",
            "4   반지하  162.032028\n",
            "..  ...         ...\n",
            "95   거주   41.465163\n",
            "96  관악구   41.230654\n",
            "97   필요   41.088125\n",
            "98  가운데   40.519907\n",
            "99  양방향   40.496039\n",
            "\n",
            "[100 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat([top_20vocab_20percent['내용'],top_50vocab_20percent['내용']],axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "yrlRRPiBjf3O",
        "outputId": "a6f17477-5396-4ac0-c51c-c056d83234a3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     내용  \\\n",
              "0     지난해 서울시에서 발생한 풍수해 피해로는 인명피해(사망) 8명, 시설피해 2만여 건...   \n",
              "1     서울시는 10일 기록적인 폭우로 침수 피해를 입은 '지하․반지하 거주가구를 위한 안...   \n",
              "2     서울시에 위치한 반지하 주택은 약 23만 가구다. 이중 침수방지시설 설치가 필요한 ...   \n",
              "3     서울시가 중증 장애인이 거주하는 침수 취약 반지하 가구에 차수판 등 침수방지시설 설...   \n",
              "4     관악구청 전경©열린뉴스통신ONA 서울시 관악구(구청장 박준희)가 집중호우로 인한 침...   \n",
              "...                                                 ...   \n",
              "1195  구체적으로는 자연재해위험개선지구, 침수취약지역, 침수이력이 있는 주거지역이 30% ...   \n",
              "1196  서울시가 저소득층의 열악한 주거환경을 개선하는 '희망의 집수리' 사업에 참여할 1,...   \n",
              "1197  서울시 관악구가 여름철 발생하는 폭염‧풍수해 등 각종 재해와 안전사고를 예방하고 구...   \n",
              "1198  대책, 서울시 피해현황 및 지원 필요사항 등을 논의했다. 이상민 중대본부장(행안부 ...   \n",
              "1199  보조금은 단열·방수 등 주택성능 개선, 침수·화재 방재를 위한 안전시설 설치, 편의...   \n",
              "\n",
              "                                                     내용  \n",
              "0     지난해 서울시에서 발생한 풍수해 피해로는 인명피해(사망) 8명, 시설피해 2만여 건...  \n",
              "1     하천 범람 시 자치구 공동 대응, 침수취약가구에 3만 5000개 침수방지시설 설치 ...  \n",
              "2     서울시 한강사업본부는 중부지방 집중호우로 한강 수위가 급변함에 따라 전체 11개 한...  \n",
              "3     한강공원 침수 구역도 넓어진 데 따른 조치다. 특히 하천 주변은 호우 피해 위험 지...  \n",
              "4     서울시는 기록적인 폭우에 대비해 강남역과 광화문, 도림천 일대 3곳에 '대심도 빗물...  \n",
              "...                                                 ...  \n",
              "1195  서울시에 따르면 시 소방재난본부는 시민 구조뿐 아니라 위험요소 사전 안전조치 131...  \n",
              "1196  최근 집중호우로 수해를 겪은 서울시가 수해방지 대책으로 일명 ‘지하 빗물 터널’ 건...  \n",
              "1197  서울시는 '반지하 특정바우처'를 거주지 동주민센터에서 상시 신청받는다. 반지하 거주...  \n",
              "1198  훈련은 협회와 행정안전부, 서울시, 송파구 등 민·관 합동으로 이뤄진다. 훈련은 한...  \n",
              "1199  서울시 동작구는 겨울철 한파에 취약한 저소득 가구의 주거환경을 개선하기 위해 '따뜻...  \n",
              "\n",
              "[1200 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c560fbbb-cf0b-41ec-8b79-b743297ece7d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>내용</th>\n",
              "      <th>내용</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>지난해 서울시에서 발생한 풍수해 피해로는 인명피해(사망) 8명, 시설피해 2만여 건...</td>\n",
              "      <td>지난해 서울시에서 발생한 풍수해 피해로는 인명피해(사망) 8명, 시설피해 2만여 건...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>서울시는 10일 기록적인 폭우로 침수 피해를 입은 '지하․반지하 거주가구를 위한 안...</td>\n",
              "      <td>하천 범람 시 자치구 공동 대응, 침수취약가구에 3만 5000개 침수방지시설 설치 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>서울시에 위치한 반지하 주택은 약 23만 가구다. 이중 침수방지시설 설치가 필요한 ...</td>\n",
              "      <td>서울시 한강사업본부는 중부지방 집중호우로 한강 수위가 급변함에 따라 전체 11개 한...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>서울시가 중증 장애인이 거주하는 침수 취약 반지하 가구에 차수판 등 침수방지시설 설...</td>\n",
              "      <td>한강공원 침수 구역도 넓어진 데 따른 조치다. 특히 하천 주변은 호우 피해 위험 지...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>관악구청 전경©열린뉴스통신ONA 서울시 관악구(구청장 박준희)가 집중호우로 인한 침...</td>\n",
              "      <td>서울시는 기록적인 폭우에 대비해 강남역과 광화문, 도림천 일대 3곳에 '대심도 빗물...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1195</th>\n",
              "      <td>구체적으로는 자연재해위험개선지구, 침수취약지역, 침수이력이 있는 주거지역이 30% ...</td>\n",
              "      <td>서울시에 따르면 시 소방재난본부는 시민 구조뿐 아니라 위험요소 사전 안전조치 131...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1196</th>\n",
              "      <td>서울시가 저소득층의 열악한 주거환경을 개선하는 '희망의 집수리' 사업에 참여할 1,...</td>\n",
              "      <td>최근 집중호우로 수해를 겪은 서울시가 수해방지 대책으로 일명 ‘지하 빗물 터널’ 건...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1197</th>\n",
              "      <td>서울시 관악구가 여름철 발생하는 폭염‧풍수해 등 각종 재해와 안전사고를 예방하고 구...</td>\n",
              "      <td>서울시는 '반지하 특정바우처'를 거주지 동주민센터에서 상시 신청받는다. 반지하 거주...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1198</th>\n",
              "      <td>대책, 서울시 피해현황 및 지원 필요사항 등을 논의했다. 이상민 중대본부장(행안부 ...</td>\n",
              "      <td>훈련은 협회와 행정안전부, 서울시, 송파구 등 민·관 합동으로 이뤄진다. 훈련은 한...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199</th>\n",
              "      <td>보조금은 단열·방수 등 주택성능 개선, 침수·화재 방재를 위한 안전시설 설치, 편의...</td>\n",
              "      <td>서울시 동작구는 겨울철 한파에 취약한 저소득 가구의 주거환경을 개선하기 위해 '따뜻...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1200 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c560fbbb-cf0b-41ec-8b79-b743297ece7d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c560fbbb-cf0b-41ec-8b79-b743297ece7d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c560fbbb-cf0b-41ec-8b79-b743297ece7d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2a7f7049-e1b8-4f27-91ce-79bd08da67b2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2a7f7049-e1b8-4f27-91ce-79bd08da67b2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2a7f7049-e1b8-4f27-91ce-79bd08da67b2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 1200,\n  \"fields\": [\n    {\n      \"column\": \"\\ub0b4\\uc6a9\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1200,\n        \"samples\": [\n          \"\\uba3c\\uc800 \\uc800\\uc9c0\\ub300 \\uc9c0\\ud558 \\uc8fc\\ud0dd \\uce68\\uc218 \\ubc29\\uc9c0\\uc0ac\\uc5c5\\uc744 \\ube44\\ub86f\\ud574 \\uc9d1\\uc911\\ud638\\uc6b0\\ub85c \\uc778\\ud55c \\ub178\\ud6c4 \\uc0ac\\ud68c\\uae30\\ubc18\\uc2dc\\uc124 \\uc815\\ube44\\uc5d0 \\ucd1d 24\\uc5b5\\uc6d0\\uc744 \\ucd94\\uac00 \\ud3b8\\uc131\\ud588\\ub2e4. \\uad6c\\ub9bd\\ub178\\uc778\\ubcf5\\uc9c0\\uc2dc\\uc124 \\uc804\\ub3d9\\uce68\\ub300 \\uc9c0\\uc6d0(5\\uc5b51000\\ub9cc\\uc6d0), \\uc774\\ucd0c\\uace0\\uac00\\ucc28\\ub3c4 \\ub0b4\\uc9c4\\uc131\\ub2a5 \\ubcf4\\uac15\\uacf5\\uc0ac(22\\uc5b53000\\ub9cc\\uc6d0), \\uac00\\ub85c\\ub4f1 \\ubc0f \\ubcf4\\uc548\\ub4f1 \\uc720\\uc9c0\\uad00\\ub9ac(4\\uc5b55000\\ub9cc\\uc6d0), \\uc81c\\uc124 \\ub300\\ucc45(2\\uc5b59000\\ub9cc\\uc6d0) \\ub4f1 \\uad6c\\ubbfc \\uc548\\uc804\\uc744...\",\n          \"\\ub610\\ud55c \\uc11c\\uc6b8\\uc2dc\\ub294 \\uc0c1\\uc2b5 \\uce68\\uc218 \\ub610\\ub294 \\uce68\\uc218 \\uc6b0\\ub824 \\uad6c\\uc5ed\\uc744 \\ubaa8\\uc544\\uc8fc\\ud0dd\\uc73c\\ub85c \\ud65c\\uc6a9\\ud558\\uac70\\ub098 \\uc7ac\\uac1c\\ubc1c\\ud558\\ub3c4\\ub85d \\ubc1c\\ube60\\ub974\\uac8c \\uc6c0\\uc9c1\\uc774\\uae30\\ub85c \\ud588\\ub2e4. \\uc774 \\uc9c0\\uc5ed\\uc758 \\uc9c0\\ud558\\u00b7\\ubc18\\uc9c0\\ud558 \\uc8fc\\ud0dd\\uc5d0\\uc11c \\uac70\\uc8fc\\ud558\\ub294 \\uc138\\uc785\\uc790\\ub4e4\\uc5d0\\uac8c\\ub294 \\uacf5\\uacf5\\uc784\\ub300\\uc8fc\\ud0dd\\uc73c\\ub85c \\uc785\\uc8fc\\ud558\\ub3c4\\ub85d \\ub3d5\\uac70\\ub098 \\uc8fc\\uac70\\ubc14\\uc6b0\\ucc98\\ub97c \\uc81c\\uacf5\\ud55c\\ub2e4. \\ubaa8\\uc544\\uc8fc\\ud0dd\\uc740 \\uc8fc\\ud0dd \\uc18c\\uc720\\uc790\\ub4e4\\uc774 \\uac1c\\ubcc4 \\ud544\\uc9c0\\ub97c \\ubaa8\\uc544 \\uc8fc\\ud0dd\\uc744 \\uacf5\\ub3d9...\",\n          \"\\uc11c\\uc6b8\\uc2dc\\uac00 \\ub300\\uaddc\\ubaa8 \\uce68\\uc218\\ub97c \\ubc29\\uc9c0\\ud558\\uae30 \\uc704\\ud574 \\uce68\\uc218\\ucde8\\uc57d\\uc9c0\\uc5ed \\uac15\\ub0a8\\uc5ed\\u2027\\uad11\\ud654\\ubb38\\u2027\\ub3c4\\ub9bc\\ucc9c \\uc77c\\ub300 3\\uac1c\\uc18c\\uc5d0 \\uc124\\uce58\\ub97c \\ubc1c\\ud45c\\ud55c \\u2018\\ub300\\uc2ec\\ub3c4 \\ube57\\ubb3c\\ubc30\\uc218\\ud130\\ub110\\u2019 1\\ub2e8\\uacc4 \\uc0ac\\uc5c5\\uc744 \\ubcf8\\uaca9\\ud654\\ud55c\\ub2e4. \\u2018\\ub300\\uc2ec\\ub3c4 \\ube57\\ubb3c\\ubc30\\uc218\\ud130\\ub110\\u2019\\uc740 \\uc9c0\\ud558 40~50m \\uc544\\ub798\\uc5d0 \\ud070 \\ud130\\ub110\\uc744 \\ub9cc\\ub4e4\\uc5b4 \\ud3ed\\uc6b0 \\uc2dc \\ube57\\ubb3c\\uc744 \\ubcf4\\uad00\\ud558\\uace0 \\ud558\\ucc9c\\uc73c\\ub85c \\ubc29\\ub958\\ud558\\ub294 \\uc2dc\\uc124\\uc774\\ub2e4. \\uc9c0\\ub09c 8\\uc6d4 \\uae30\\ub85d\\uc801\\uc778...\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ub0b4\\uc6a9\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1200,\n        \"samples\": [\n          \"\\ud55c\\ud3b8, \\uc7a0\\uc218\\uad50 \\uc591\\ubc29\\ud5a5\\uc740 \\uc5ec\\uc804\\ud788 \\uad50\\ud1b5\\uc774 \\ud1b5\\uc81c\\ub418\\uace0 \\uc788\\uc2b5\\ub2c8\\ub2e4. \\uc7a0\\uc218\\uad50\\ub294 \\uc218\\uc704\\uac00 6.5\\uff4d\\uc5d0 \\uc774\\ub974\\uba74 \\ub3c4\\ub85c\\uc5d0 \\ubb3c\\uc774 \\ucc28\\ub294\\ub370, \\uc11c\\uc6b8\\uc2dc\\ub294 \\ucc28\\ub7c9 \\uce68\\uc218\\ub97c \\ub9c9\\uae30 \\uc704\\ud574 \\uc7a0\\uc218\\uad50 \\uc9c0\\uc810 \\uc218\\uc704\\uac00 6.2\\uff4d\\ub97c \\ub118\\uc73c\\uba74 \\ucc28\\ub7c9 \\ud1b5\\ud589\\uc744 \\ud1b5\\uc81c\\ud569\\ub2c8\\ub2e4. \\uc624\\uc804 5\\uc2dc \\uae30\\uc900 \\ud604\\uc7ac \\uc218\\uc704\\ub294 7.38\\uff4d\\uc785\\ub2c8\\ub2e4. [\\uc0ac\\uc9c4 \\ucd9c\\ucc98 : \\uc5f0\\ud569\\ub274\\uc2a4]\",\n          \"\\ud558\\uc9c0\\ub9cc \\uc11c\\uc6b8\\uc2dc\\uc758 \\uce68\\uc218\\uc6b0\\ub824\\uc9c0\\uc5ed \\uc18c\\uc7ac \\uc544\\ud30c\\ud2b8 13\\uac1c \\ub2e8\\uc9c0 \\uc911 10\\uac1c \\ub2e8\\uc9c0\\uac00 \\uc9c0\\ud558\\uc8fc\\ucc28\\uc7a5 \\ubb3c\\ub9c9\\uc774\\ud310\\uc774 \\uc5c6\\uc5b4 \\uc5ec\\uc804\\ud788 \\uc124\\uce58\\uc728\\uc774 \\ubbf8\\ud761\\ud55c \\uac83\\uc73c\\ub85c \\uc870\\uc0ac\\ub410\\ub2e4. \\ubb38\\uc81c\\ub294 \\uc62c\\uc5ec\\ub984 \\uc11c\\uc6b8\\u00b7\\uacbd\\uae30 \\uac15\\uc218\\ub7c9\\uc740 \\ud3c9\\ub144 \\ub300\\ube44 \\ub192\\uc744 \\uac83\\uc774\\ub77c\\ub294 \\uae30\\uc0c1\\uccad \\uc608\\ubcf4\\uc5d0 \\ub530\\ub77c \\ucc28\\ub7c9\\uce68\\uc218 \\uc704\\ud5d8 \\uac00\\ub2a5\\uc131\\uc740 \\ub354\\uc6b1 \\ucee4\\uc9c8 \\uac83\\uc774\\ub780 \\uc6b0\\ub824\\ub2e4. \\uc774\\uc5d0 \\ub530\\ub77c \\ucc28\\ub7c9\\uce68\\uc218 \\uc608\\ubc29\\uc744 \\uc704\\ud55c...\",\n          \"\\uc11c\\uc6b8\\uad50\\ud1b5\\uacf5\\uc0ac\\ub294 \\uc9c0\\ud558\\ucca0\\uc5ed \\uce68\\uc218\\ub97c \\ub9c9\\uae30\\uc704\\ud574 \\ucc28\\uc218\\ud310\\uc744 \\uc124\\uce58\\ud558\\uace0 \\ud3ed\\uc6b0\\uc2dc \\uc9c0\\ud558\\ucca0 \\uc6b4\\ud589\\uc744 \\uc5f0\\uc7a5\\ud55c\\ub2e4. \\uc11c\\uc6b8\\uc2dc \\uc18c\\ubc29\\uc7ac\\ub09c\\ubcf8\\ubd80\\ub294 \\uc62c\\uc5ec\\ub984 \\ud734\\uac00\\ucca0 \\uc2dc\\ubbfc\\ub4e4\\uc758 \\uc774\\uc6a9\\uc774 \\ub9ce\\uc744 \\uac83\\uc73c\\ub85c \\uc608\\uc0c1\\ub418\\ub294 \\ud638\\ud154 \\ub4f1 \\ub2e4\\uc911\\uc774\\uc6a9\\uc2dc\\uc124\\uc744 \\ub300\\uc0c1\\uc73c\\ub85c \\ud654\\uc7ac \\uc548\\uc804\\uad00\\ub9ac\\ub300\\ucc45\\uc744 \\ucd94\\uc9c4\\ud55c\\ub2e4. \\uc11c\\uc6b8\\uc2dc\\uc124\\uacf5\\ub2e8\\uc740 \\uc6b0\\ud3b8\\ubb3c\\uc774 \\ubb3c\\uc5d0 \\uc816\\uc9c0 \\uc54a\\ub3c4\\ub85d \\ucde8\\uc57d\\uac00\\uad6c\\ub97c \\ub300\\uc0c1\\uc73c\\ub85c...\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Mecab 형태소 분석 활용"
      ],
      "metadata": {
        "id": "7SeSYpkiYnPS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import urllib.request\n",
        "\n",
        "from konlpy.tag import *\n",
        "\n",
        "hannanum = Hannanum()\n",
        "kkma = Kkma()\n",
        "komoran = Komoran()\n",
        "okt = Okt()\n",
        "mecab = Mecab()\n",
        "\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "# 등장빈도수 count 하기 위함"
      ],
      "metadata": {
        "id": "oRnewoOZYZGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AWnYx-SPywjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "제목_mecab = []\n",
        "\n",
        "for sentence in tqdm(df['제목'].apply(lambda x: re.sub(r\"[^a-zA-Z0-9ㄱ-ㅎ가-힣]\", \" \", x))):\n",
        "    tokenized_sentence = mecab.morphs(sentence) # 토큰화\n",
        "    stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords] # 불용어 제거\n",
        "    제목_mecab.append(stopwords_removed_sentence)"
      ],
      "metadata": {
        "id": "-ix1ouSbc2Ga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "본문_mecab = []\n",
        "\n",
        "for sentence in tqdm(df['content'].apply(lambda x: re.sub(r\"[^a-zA-Z0-9ㄱ-ㅎ가-힣']\", \" \", x))):\n",
        "    tokenized_sentence = mecab.morphs(sentence) # 토큰화\n",
        "    stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords] # 불용어 제거\n",
        "    본문_mecab.append(stopwords_removed_sentence)"
      ],
      "metadata": {
        "id": "UStS_U5Ddbwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_list = []\n",
        "\n",
        "for sent in 제목_mecab:\n",
        "    for word in sent:\n",
        "        word_list.append(word)\n",
        "\n",
        "word_counts = Counter(word_list)\n",
        "print(\"총 단어 수:\", len(word_counts))"
      ],
      "metadata": {
        "id": "K2Z7WM3Rdk34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_counts)"
      ],
      "metadata": {
        "id": "GCHdiGfMd6vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = sorted(word_counts, key=word_counts.get, reverse=True) # 내림차순\n",
        "print('등장 빈도 수 상위 10개 단어:' , vocab[:10])"
      ],
      "metadata": {
        "id": "w2kfw18meLSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 3 # 임계치(기준)\n",
        "\n",
        "total_cnt = len(word_counts) # 단어 수\n",
        "rare_cnt = 0\n",
        "# 등장 빈도수가 threshold 보다 작은 단어의 개수를 카운트 하기 위해 초기화\n",
        "total_freq = 0\n",
        "# 훈련 데이터의 전체 단어 빈도수의 총 합 구하기 위해 초기화\n",
        "rare_freq = 0\n",
        "# 등장 빈도수가 threshold 보다 작은 단어의 등장 빈도수의 총 합 초기화\n",
        "\n",
        "# 단어(key)와 빈도수(value) 의 쌍(pair)을 key와 value 로 받는다\n",
        "\n",
        "for key, value in word_counts.items():\n",
        "   total_freq = total_freq + value\n",
        "\n",
        "   # 단어의 등장 빈도수가 threshold 보다 작으면\n",
        "   if (value < threshold):\n",
        "      rare_cnt = rare_cnt + 1\n",
        "      rare_freq = rare_freq + value\n",
        "\n",
        "print('단어 집합(vocabulary) 크기:', total_cnt)\n",
        "print('등장 빈도가 %s번 이하인 희소 단어의 수:%s'%(threshold -1, rare_cnt))\n",
        "print('단어 집합에서 희소 단어의 비율:', (rare_cnt / total_cnt)*100)\n",
        "print('전체 등장 빈도에서 희소 단어 등장 빈도 비율:',(rare_freq / total_freq)*100)"
      ],
      "metadata": {
        "id": "RxDHQxO3eb8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 단어 개수 중에서 빈도수 2이하인 단어는 단어는 제거 (등장빈도수로 정렬된 상태임)\n",
        "\n",
        "vocab_size = total_cnt - rare_cnt\n",
        "print(vocab_size)\n",
        "print(vocab[:vocab_size])"
      ],
      "metadata": {
        "id": "p-20Vgewfjwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = vocab[:vocab_size]\n",
        "len(vocab)"
      ],
      "metadata": {
        "id": "VRnU2IAJfyE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정수인코딩\n",
        "word_to_index = {}\n",
        "word_to_index['<PAD>'] = 0\n",
        "word_to_index['<UNK>'] = 1 # OOV : Out of Vocabulary"
      ],
      "metadata": {
        "id": "PJD0CE6rf2pN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for index, word in enumerate(vocab):\n",
        "    word_to_index[word] = index + 2"
      ],
      "metadata": {
        "id": "SdnSQ4E8gHZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_to_index)"
      ],
      "metadata": {
        "id": "P5bKkFtggUwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(word_to_index)"
      ],
      "metadata": {
        "id": "v6IcCvYFgWbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index['침수']"
      ],
      "metadata": {
        "id": "9TBYWHNEgePc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def texts_to_sequences(tokenized_x_data, word_to_index):\n",
        "    encoded_x_data = []\n",
        "    for sent in tokenized_x_data:\n",
        "        index_sequences = []\n",
        "        for word in sent:\n",
        "            try:\n",
        "                index_sequences.append(word_to_index[word])\n",
        "\n",
        "            except KeyError:\n",
        "                index_sequences.append(word_to_index['<UNK>'])\n",
        "        encoded_x_data.append(index_sequences)\n",
        "\n",
        "    return encoded_x_data"
      ],
      "metadata": {
        "id": "rRfFtD2CgiRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_제목_mecab = texts_to_sequences(제목_mecab, word_to_index)"
      ],
      "metadata": {
        "id": "aBRJbhAiYcr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(encoded_제목_mecab[:10])"
      ],
      "metadata": {
        "id": "YA5bBCMTYiB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_제목_mecab[0]"
      ],
      "metadata": {
        "id": "ArwmbdVzYxy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_본문_mecab = texts_to_sequences(본문_mecab, word_to_index)\n",
        "print(encoded_본문_mecab[:10])\n",
        "print(encoded_본문_mecab[0])"
      ],
      "metadata": {
        "id": "_xfSevMUY6-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_word = {}\n",
        "for key, value in word_to_index.items():\n",
        "    index_to_word[value] = key"
      ],
      "metadata": {
        "id": "X9i-aUemY_YS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[index_to_word[word] for word in encoded_제목_mecab[0]]"
      ],
      "metadata": {
        "id": "bO0UUlWdZnD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_sample = [index_to_word[word] for word in encoded_제목_mecab[0]]"
      ],
      "metadata": {
        "id": "sCQ28a-5ZxxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('기존의 첫번째 샘플:', 제목_mecab[0])\n",
        "print('복원 전 정수 인코딩된 첫번째 샘플', encoded_제목_mecab[0])\n",
        "print('복원된 첫번째 샘플:', decoded_sample)"
      ],
      "metadata": {
        "id": "JXmqJPqhZ3X5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print([review for review in encoded_제목_mecab][:5])"
      ],
      "metadata": {
        "id": "T4kMWkmlZ_wj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('각 리뷰의 길이:', [len(review) for review in encoded_제목_mecab])\n",
        "print('리뷰의 최대 길이:', max([len(review) for review in encoded_제목_mecab]))\n",
        "print('리뷰의 평균 길이:',sum(map(len, encoded_제목_mecab)) / len(encoded_제목_mecab))\n",
        "\n",
        "plt.hist([len(review) for review in encoded_제목_mecab], bins=50)\n",
        "plt.xlabel('length of samples') # 리뷰의 단어 길이\n",
        "plt.ylabel('number of samples') # 리뷰의 단어 수\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DhWIC5VnaIkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def below_threshold_len(max_len, nested_list):\n",
        "    count = 0\n",
        "    for sentence in nested_list:\n",
        "        if (len(sentence) <= max_len):\n",
        "            count = count + 1\n",
        "    print('전체 샘플 중 길이가 %s 이하인 샘플 비율:%s'%(max_len, (count/len(nested_list))*100))"
      ],
      "metadata": {
        "id": "oJ2-bM0Ta9Hc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 80\n",
        "# 최대 길이 80으로 할 때\n",
        "below_threshold_len(max_len, encoded_제목_mecab)"
      ],
      "metadata": {
        "id": "ZfrCHlSlbU7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_sequences(sentences, max_len):\n",
        "    features = np.zeros((len(sentences), max_len), dtype=int)\n",
        "    for index, sentence in enumerate(sentences):\n",
        "        if len(sentence) != 0:\n",
        "            features[index, :len(sentence)] = np.array(sentence)[:max_len]\n",
        "    return features"
      ],
      "metadata": {
        "id": "c97EN0kBboHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pad_sequences(encoded_제목_mecab, max_len)"
      ],
      "metadata": {
        "id": "xZpzNZfQcd3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_x_train = pad_sequences(encoded_제목_mecab, max_len)"
      ],
      "metadata": {
        "id": "XcXg6y5hcil9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#mecab 본문\n"
      ],
      "metadata": {
        "id": "wTofZ1sO2aFD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_d78Hw9I2cL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "본문_mecab = []\n",
        "\n",
        "for sentence in tqdm(df['content'].apply(lambda x: re.sub(r\"[^a-zA-Z0-9ㄱ-ㅎ가-힣']\", \" \", x))):\n",
        "    tokenized_sentence = mecab.morphs(sentence) # 토큰화\n",
        "    stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords and len(word) >= 2] # 불용어 제거\n",
        "    본문_mecab.append(stopwords_removed_sentence)"
      ],
      "metadata": {
        "id": "iOV7rHBl2tYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_hEMcH-RbgIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_list = []\n",
        "\n",
        "for sent in 본문_mecab:\n",
        "    for word in sent:\n",
        "        word_list.append(word)\n",
        "\n",
        "word_counts = Counter(word_list)\n",
        "print(\"총 단어 수:\", len(word_counts))"
      ],
      "metadata": {
        "id": "EZtk5Eiu2tYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_counts)"
      ],
      "metadata": {
        "id": "2-pQuzCM2tYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = sorted(word_counts, key=word_counts.get, reverse=True) # 내림차순\n",
        "print('등장 빈도 수 상위 50개 단어:' , vocab[:50])"
      ],
      "metadata": {
        "id": "HzZlPv2S2tYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab[:20] ,"
      ],
      "metadata": {
        "id": "RWIqQd9lX54W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 3 # 임계치(기준)\n",
        "\n",
        "total_cnt = len(word_counts) # 단어 수\n",
        "rare_cnt = 0\n",
        "# 등장 빈도수가 threshold 보다 작은 단어의 개수를 카운트 하기 위해 초기화\n",
        "total_freq = 0\n",
        "# 훈련 데이터의 전체 단어 빈도수의 총 합 구하기 위해 초기화\n",
        "rare_freq = 0\n",
        "# 등장 빈도수가 threshold 보다 작은 단어의 등장 빈도수의 총 합 초기화\n",
        "\n",
        "# 단어(key)와 빈도수(value) 의 쌍(pair)을 key와 value 로 받는다\n",
        "\n",
        "for key, value in word_counts.items():\n",
        "   total_freq = total_freq + value\n",
        "\n",
        "   # 단어의 등장 빈도수가 threshold 보다 작으면\n",
        "   if (value < threshold):\n",
        "      rare_cnt = rare_cnt + 1\n",
        "      rare_freq = rare_freq + value\n",
        "\n",
        "print('단어 집합(vocabulary) 크기:', total_cnt)\n",
        "print('등장 빈도가 %s번 이하인 희소 단어의 수:%s'%(threshold -1, rare_cnt))\n",
        "print('단어 집합에서 희소 단어의 비율:', (rare_cnt / total_cnt)*100)\n",
        "print('전체 등장 빈도에서 희소 단어 등장 빈도 비율:',(rare_freq / total_freq)*100)"
      ],
      "metadata": {
        "id": "nPWYgVSD2tYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 단어 개수 중에서 빈도수 2이하인 단어는 단어는 제거 (등장빈도수로 정렬된 상태임)\n",
        "\n",
        "vocab_size = total_cnt - rare_cnt\n",
        "print(vocab_size)\n",
        "print(vocab[:vocab_size])"
      ],
      "metadata": {
        "id": "OCJDeV132tYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = vocab[:vocab_size]\n",
        "len(vocab)"
      ],
      "metadata": {
        "id": "bMNCS1v72tYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정수인코딩\n",
        "word_to_index = {}\n",
        "word_to_index['<PAD>'] = 0\n",
        "word_to_index['<UNK>'] = 1 # OOV : Out of Vocabulary"
      ],
      "metadata": {
        "id": "veNCBvcp2tYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for index, word in enumerate(vocab):\n",
        "    word_to_index[word] = index + 2"
      ],
      "metadata": {
        "id": "WwkJW0742tYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_to_index)"
      ],
      "metadata": {
        "id": "sNvi4hK82tYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(word_to_index)"
      ],
      "metadata": {
        "id": "sfAhQ7Ww2tYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index['침수']"
      ],
      "metadata": {
        "id": "wAhHmPKO2tYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def texts_to_sequences(tokenized_x_data, word_to_index):\n",
        "    encoded_x_data = []\n",
        "    for sent in tokenized_x_data:\n",
        "        index_sequences = []\n",
        "        for word in sent:\n",
        "            try:\n",
        "                index_sequences.append(word_to_index[word])\n",
        "\n",
        "            except KeyError:\n",
        "                index_sequences.append(word_to_index['<UNK>'])\n",
        "        encoded_x_data.append(index_sequences)\n",
        "\n",
        "    return encoded_x_data"
      ],
      "metadata": {
        "id": "P3__0NVr2tYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_본문_mecab = texts_to_sequences(본문_mecab, word_to_index)"
      ],
      "metadata": {
        "id": "mLgKN0S-2tYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(encoded_본문_mecab[:10])"
      ],
      "metadata": {
        "id": "-DXCtA2m2tYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_본문_mecab[0]"
      ],
      "metadata": {
        "id": "HvdS2cbM2tYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_본문_mecab = texts_to_sequences(본문_mecab, word_to_index)\n",
        "print(encoded_본문_mecab[:10])\n",
        "print(encoded_본문_mecab[0])"
      ],
      "metadata": {
        "id": "Fd9OSTKe2tYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_word = {}\n",
        "for key, value in word_to_index.items():\n",
        "    index_to_word[value] = key"
      ],
      "metadata": {
        "id": "cA_-WNqv2tYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[index_to_word[word] for word in encoded_제목_mecab[0]]"
      ],
      "metadata": {
        "id": "OWAlYhTu2tYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_sample = [index_to_word[word] for word in encoded_본문_mecab[0]]"
      ],
      "metadata": {
        "id": "p0IxjZrU2tYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LRnReTuV29ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('기존의 첫번째 샘플:', 본문_mecab[0])\n",
        "print('복원 전 정수 인코딩된 첫번째 샘플', encoded_본문_mecab[0])\n",
        "print('복원된 첫번째 샘플:', decoded_sample)"
      ],
      "metadata": {
        "id": "8iziUuvU2tYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print([review for review in encoded_본문_mecab][:5])"
      ],
      "metadata": {
        "id": "DGrGfwoj2tYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('각 리뷰의 길이:', [len(review) for review in encoded_본문_mecab])\n",
        "print('리뷰의 최대 길이:', max([len(review) for review in encoded_본문_mecab]))\n",
        "print('리뷰의 평균 길이:',sum(map(len, encoded_본문_mecab)) / len(encoded_본문_mecab))\n",
        "\n",
        "plt.hist([len(review) for review in encoded_본문_mecab], bins=50)\n",
        "plt.xlabel('length of samples') # 리뷰의 단어 길이\n",
        "plt.ylabel('number of samples') # 리뷰의 단어 수\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AYCuIveJ2tYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def below_threshold_len(max_len, nested_list):\n",
        "    count = 0\n",
        "    for sentence in nested_list:\n",
        "        if (len(sentence) <= max_len):\n",
        "            count = count + 1\n",
        "    print('전체 샘플 중 길이가 %s 이하인 샘플 비율:%s'%(max_len, (count/len(nested_list))*100))"
      ],
      "metadata": {
        "id": "sxPJFOJI2tYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 80\n",
        "# 최대 길이 80으로 할 때\n",
        "below_threshold_len(max_len, encoded_본문_mecab)"
      ],
      "metadata": {
        "id": "zIjLlSaU2tYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_sequences(sentences, max_len):\n",
        "    features = np.zeros((len(sentences), max_len), dtype=int)\n",
        "    for index, sentence in enumerate(sentences):\n",
        "        if len(sentence) != 0:\n",
        "            features[index, :len(sentence)] = np.array(sentence)[:max_len]\n",
        "    return features"
      ],
      "metadata": {
        "id": "ZMkBuxsL2tYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pad_sequences(encoded_본문_mecab, max_len)"
      ],
      "metadata": {
        "id": "wcxo_T-W2tYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#nltk word_tokenized 전처리"
      ],
      "metadata": {
        "id": "poJ9wMtSgb8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import torch\n",
        "import urllib.request\n",
        "\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "SWwR2i8odDDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "k8BUTd4xgin_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "SEED = 1234\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "Np_nTTZEgpOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "id": "UstyTacKhK3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/filtered_flood_news_ver02.csv'"
      ],
      "metadata": {
        "id": "1HZ90cjAhWZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(path)[['제목','content']]\n",
        "df[:2]"
      ],
      "metadata": {
        "id": "CAzCJQDxhhog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(sentences):\n",
        "  tokenized_sentences = []\n",
        "  for sent in tqdm(sentences):\n",
        "    tokenized_sent = word_tokenize(sent)\n",
        "    tokenized_sent = [word.lower() for word in tokenized_sent]\n",
        "    tokenized_sentences.append(tokenized_sent)\n",
        "  return tokenized_sentences"
      ],
      "metadata": {
        "id": "7wTzSGTIjEfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_x_train = tokenize(df['제목'].apply(lambda x: re.sub(r\"[^a-zA-Z0-9ㄱ-ㅎ가-힣]\", \" \", x)))\n",
        "tokenized_x_test = tokenize(df['content'].apply(lambda x: re.sub(r\"[^a-zA-Z0-9ㄱ-ㅎ가-힣]\", \" \", x)))\n",
        "tokenized_x_train = tokenize(df['content'].apply(lambda x: re.sub(r\"[^a-zA-Z0-9ㄱ-ㅎ가-힣]\", \" \", x)))\n"
      ],
      "metadata": {
        "id": "qIWCXD4hjoPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 상위 샘플 2개 출력\n",
        "\n",
        "for sent in tokenized_x_train[:2]:\n",
        "    print(sent)"
      ],
      "metadata": {
        "id": "PVtTqAtjj6MX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_list = []\n",
        "\n",
        "for sent in tokenized_x_train:\n",
        "  for word in sent:\n",
        "    word_list.append(word)\n",
        "\n",
        "word_counts = Counter(word_list)\n",
        "print('총 단어수:', len(word_counts))"
      ],
      "metadata": {
        "id": "VNdu2H0MkAuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_counts)"
      ],
      "metadata": {
        "id": "qCayjofxkJ45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('훈련 데이터에서의 단어 서울의 등장 횟수:', word_counts['서울시'])\n",
        "print('훈련 데이터에서의 단어 서울시의 등장 횟수:', word_counts['서울'])\n",
        "print('훈련 데이터에서의 단어 침수의 등장 횟수:', word_counts['침수'])"
      ],
      "metadata": {
        "id": "_aWIz96gkMzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('훈련 데이터에서의 단어 피해의 등장 횟수:', word_counts['피해'])"
      ],
      "metadata": {
        "id": "dCFvOpjrqyek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = sorted(word_counts, key=word_counts.get, reverse=True) # 내림차순\n",
        "print(vocab[:10])"
      ],
      "metadata": {
        "id": "WB_Q4D00kdwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 3\n",
        "total_cnt = len(word_counts)\n",
        "\n",
        "rare_cnt = 0    # 등장 빈도수가 threshold 보다 작은 단어 개수 세기\n",
        "total_freq = 0  # 훈련 데이터의 전체 단어 빈도수 총 합\n",
        "rare_freq = 0   # 등장 빈도수가 threshold 보다 작은 단어 등장 빈도수의 총 합\n",
        "\n",
        "# 단어와 빈도수 쌍(pair) >> key, value\n",
        "\n",
        "for key, value in word_counts.items():\n",
        "  total_freq = total_freq + value\n",
        "\n",
        "  # 단어 등장 빈도수가 threshold 보다 작으면\n",
        "  if (value < threshold):\n",
        "    rare_cnt = rare_cnt + 1\n",
        "    rare_freq = rare_freq + value\n",
        "\n",
        "print('단어 집합(vocabulary)의 크기:', total_cnt)\n",
        "print('등장 빈도가 %s번 이하인 희귀 단어 수:%s'%(threshold - 1, rare_cnt))\n",
        "print('단어 집합에서 희귀 단어 비율:', (rare_cnt / total_cnt)*100)\n",
        "print('전체 등장 빈도에서 희귀 단어 등장 빈도 비율:', (rare_freq / total_freq) * 100)"
      ],
      "metadata": {
        "id": "xGHtZnV0krrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = total_cnt - rare_cnt\n",
        "vocab_size"
      ],
      "metadata": {
        "id": "pwdKRWaGkz0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = vocab[:vocab_size]\n",
        "len(vocab)"
      ],
      "metadata": {
        "id": "Ad62td_4k3yT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab[:100])"
      ],
      "metadata": {
        "id": "zsejlV-FlW7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정수인코딩\n",
        "word_to_index = {}\n",
        "word_to_index['<PAD>'] = 0\n",
        "word_to_index['<UNK>'] = 1"
      ],
      "metadata": {
        "id": "DW8DDNuXlamC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for index, word in enumerate(vocab):\n",
        "   word_to_index[word] = index + 2"
      ],
      "metadata": {
        "id": "-VpRlfSElfSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_to_index)"
      ],
      "metadata": {
        "id": "UbU151UVliwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(word_to_index)\n",
        "print('패딩 토큰, UNK 토큰 고려한 단어 집합 크기:', vocab_size)"
      ],
      "metadata": {
        "id": "0qQkvsUuljK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def texts_to_sequences(tokenized_x_data, word_to_index):\n",
        "  encoded_x_data =[]\n",
        "  for sent in tokenized_x_data:\n",
        "    index_sequences=[]\n",
        "    for word in sent:\n",
        "      try:\n",
        "        index_sequences.append(word_to_index[word])\n",
        "      except KeyError:\n",
        "        index_sequences.append(word_to_index['<UNK>'])\n",
        "    encoded_x_data.append(index_sequences)\n",
        "  return encoded_x_data"
      ],
      "metadata": {
        "id": "l-kAJNaglpv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_x_train[0])"
      ],
      "metadata": {
        "id": "fuDDj4KJlwNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(texts_to_sequences(tokenized_x_train, word_to_index))"
      ],
      "metadata": {
        "id": "bZU_fupfl00l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_x_train = texts_to_sequences(tokenized_x_train, word_to_index)\n",
        "encoded_x_test = texts_to_sequences(tokenized_x_test, word_to_index)"
      ],
      "metadata": {
        "id": "RfI9Koctl53R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(encoded_x_train[0])"
      ],
      "metadata": {
        "id": "wuJ6BpF6mEar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 상위 샘플 2개 출력\n",
        "\n",
        "for sent in encoded_x_train[:2]:\n",
        "  print(sent)"
      ],
      "metadata": {
        "id": "NyNEHlI8mQvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_word = {}\n",
        "\n",
        "for key, value in word_to_index.items():\n",
        "  index_to_word[value] = key"
      ],
      "metadata": {
        "id": "mXn1XmhjmWwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_to_index)\n",
        "print(index_to_word)"
      ],
      "metadata": {
        "id": "IIotLvenmW4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_sample = [index_to_word[word] for word in encoded_x_train[0]]  # 디코딩\n",
        "print(decoded_sample)"
      ],
      "metadata": {
        "id": "KDuyuDGRmXB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('기존의 첫번째 샘플:', tokenized_x_train[0])\n",
        "print('복원된 첫번째 샘플:', decoded_sample)"
      ],
      "metadata": {
        "id": "ru0R-ghdmrpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('제목의 최대 길이:', max(len(review) for review in encoded_x_train))\n",
        "print('제목의 평균 길이:', sum(map(len, encoded_x_train))/len(encoded_x_train))\n",
        "\n",
        "plt.hist([len(review) for review in encoded_x_train], bins=50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OMcYGcqvmwc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(encoded_x_train[0])"
      ],
      "metadata": {
        "id": "crWEHIlfvcSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#제목의 길이가 짧은 순으로 상위 10개 print\n",
        "for i in range(10):\n",
        "  print(encoded_x_train[i])"
      ],
      "metadata": {
        "id": "MoHobzVyvTcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def below_threshold_len(max_len, nested_list):\n",
        "  count=0\n",
        "  for sentences in nested_list:\n",
        "    if(len(sentences) <= max_len):\n",
        "      count = count + 1\n",
        "    #   print([index_to_word[word] for word in sentences]) # 디코딩\n",
        "  print('전체 샘플 중 길이가 %s 이하인 샘플 비율:%s'%(max_len, (count / len(nested_list))*100))"
      ],
      "metadata": {
        "id": "ZJAGKVLsmwmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 3\n",
        "below_threshold_len(max_len, encoded_x_train)"
      ],
      "metadata": {
        "id": "pxofYr0ImwxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_sequences(sentences, max_len):\n",
        "  features = np.zeros((len(sentences), max_len), dtype=int)\n",
        "  for index, sentences in enumerate(sentences):\n",
        "    if len(sentences) != 0:\n",
        "      features[index, :len(sentences)] = np.array(sentences)[:max_len]\n",
        "  return features"
      ],
      "metadata": {
        "id": "wabnx0wAnXXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_x_train = pad_sequences(encoded_x_train, max_len=max_len)\n",
        "padded_x_test = pad_sequences(encoded_x_test, max_len=max_len)"
      ],
      "metadata": {
        "id": "THHQR84TnYoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('훈련 데이터 크기:', padded_x_train.shape)\n",
        "print('테스트 데이터 크기:', padded_x_test.shape)"
      ],
      "metadata": {
        "id": "glircm2Fna92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_x_train[:2]"
      ],
      "metadata": {
        "id": "VqbC1FMmne_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(padded_x_train[0])"
      ],
      "metadata": {
        "id": "tIMJUmFvnfH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_x_train[0]"
      ],
      "metadata": {
        "id": "lVCN4neInfRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LLM Tokenizer\n",
        "\n",
        "# 사전학습된 언어모델 (pre-trained language model)\n",
        "# 형태소 분석 사용 안 함\n",
        "# 자체적으로 vocabulary 구축 >> 토큰화"
      ],
      "metadata": {
        "id": "GCUdfG3FnvQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "FGyEW4WDn94e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import PreTrainedTokenizerFast"
      ],
      "metadata": {
        "id": "yU0aD0A3oA0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\")"
      ],
      "metadata": {
        "id": "TkXLmtkroFeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.tokenize('열심히 코딩한 당신, 수료 후 여행을 떠나라')"
      ],
      "metadata": {
        "id": "pitRIgKPoM5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o7D9IdGYoRhn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}